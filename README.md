# ğŸï¸ Pipeline de AnÃ¡lise de Pit Stops da F1 em Tempo Real

Este projeto implementa um pipeline completo de ingestÃ£o, processamento, armazenamento e visualizaÃ§Ã£o de dados em tempo real, utilizando um dataset de pit stops da FÃ³rmula 1.

## Integrante e ParticipaÃ§Ã£o

* **Rafael Severo**: ResponsÃ¡vel pela concepÃ§Ã£o, desenvolvimento e documentaÃ§Ã£o de todo o pipeline, incluindo a configuraÃ§Ã£o da arquitetura de serviÃ§os (Docker, Kafka, Redis, RabbitMQ, MinIO), a codificaÃ§Ã£o dos scripts de ingestÃ£o e consumo, e a criaÃ§Ã£o do dashboard de visualizaÃ§Ã£o.

## Arquitetura do Pipeline

O pipeline Ã© composto pelos seguintes serviÃ§os, todos orquestrados com Docker Compose em uma Ãºnica rede:

-   **Producer (Python)**: Um script que lÃª os dados do arquivo `pit_stops.csv` e publica cada evento de pit stop em um tÃ³pico do Kafka.
-   **Kafka**: Atua como um *message broker* distribuÃ­do, recebendo os dados brutos no tÃ³pico `f1_pitstops_raw` e garantindo a entrega para os consumidores.
-   **Consumer (Python)**: O coraÃ§Ã£o do pipeline. Ele consome os dados do Kafka e executa trÃªs tarefas simultaneamente:
    1.  **Cache RÃ¡pido**: Armazena a informaÃ§Ã£o do Ãºltimo pit stop em um cache no **Redis** para acesso de baixa latÃªncia pelo dashboard.
    2.  **Sistema de Alertas**: Envia uma mensagem para uma fila no **RabbitMQ** se um pit stop demorar **mais de 25 segundos**, sinalizando um possÃ­vel problema.
    3.  **Data Lake**: Salva o registro JSON de todos os pit stops em um bucket no **MinIO**, nosso Data Lake, para armazenamento histÃ³rico e anÃ¡lises futuras.
-   **Streamlit**: Um dashboard web interativo que se conecta ao Redis para buscar e exibir os dados do Ãºltimo pit stop e o histÃ³rico de duraÃ§Ãµes em tempo real.
-   **MinIO**: Um sistema de armazenamento de objetos compatÃ­vel com a API S3, utilizado como Data Lake.
-   **Redis**: Um banco de dados em memÃ³ria, usado para cache e acesso rÃ¡pido aos dados mais recentes.
-   **RabbitMQ**: Um *message broker* tradicional, usado para gerenciar a fila de alertas crÃ­ticos.


## Como Executar o Pipeline

**PrÃ©-requisitos:**
* Docker
* Docker Compose

**Passos:**

1.  **Estrutura de Arquivos:**
    Certifique-se de que seu diretÃ³rio de projeto estÃ¡ organizado da seguinte forma:

    ```
    pipeline_f1/
    â”œâ”€â”€ docker-compose.yml
    â”œâ”€â”€ Dockerfile.producer
    â”œâ”€â”€ Dockerfile.consumer
    â”œâ”€â”€ Dockerfile.streamlit
    â”œâ”€â”€ producer.py
    â”œâ”€â”€ consumer.py
    â”œâ”€â”€ dashboard.py
    â”œâ”€â”€ requirements.txt
    â””â”€â”€ pit_stops.csv   <-- Coloque o dataset aqui!
    ```

2.  **Construa e Inicie os ContÃªineres:**
    No diretÃ³rio raiz do projeto (onde o arquivo `docker-compose.yml` estÃ¡ localizado), execute o seguinte comando no terminal:
    ```bash
    docker-compose up --build -d
    ```
    O comando `--build` garante que as imagens Docker serÃ£o construÃ­das a partir dos `Dockerfile`s, e `-d` executa os contÃªineres em modo "detached" (em segundo plano).

3.  **Acesse os ServiÃ§os:**
    ApÃ³s alguns instantes para que todos os serviÃ§os iniciem, vocÃª poderÃ¡ acessar as diferentes partes do pipeline:

    * **Dashboard em Tempo Real (Streamlit)**:
        Acesse `http://localhost:8501` no seu navegador. VocÃª verÃ¡ os dados dos pit stops sendo atualizados em tempo real.

    * **Console do MinIO (Data Lake)**:
        Acesse `http://localhost:9001`. Use as credenciais `minioadmin` / `minioadmin` para fazer login. VocÃª encontrarÃ¡ o bucket `f1-pitstops` com os arquivos JSON de cada evento sendo criados.

    * **Management UI do RabbitMQ (Alertas)**:
        Acesse `http://localhost:15672`. Use as credenciais `guest` / `guest`. Navegue atÃ© a aba "Queues" e observe a fila `pitstop_alerts`. Mensagens de alerta aparecerÃ£o aqui sempre que um pit stop demorar mais de 25 segundos.

4.  **Verifique os Logs (Opcional):**
    Para acompanhar o que cada serviÃ§o estÃ¡ fazendo em tempo real, vocÃª pode verificar os logs de um contÃªiner especÃ­fico:
    ```bash
    # Logs do producer enviando os dados
    docker logs -f producer

    # Logs do consumer processando os dados
    docker logs -f consumer
    ```

5.  **Para Parar o Pipeline:**
    Para parar e remover todos os contÃªineres, redes e volumes criados, execute o seguinte comando no mesmo diretÃ³rio:
    ```bash
    docker-compose down
    ```
